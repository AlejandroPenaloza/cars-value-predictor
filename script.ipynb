{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import re\n",
    "import requests\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_agg\n",
    "import matplotlib.figure\n",
    "% matplotlib inline\n",
    "import seaborn as sb\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML soups from all 500 web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soups(website_number):\n",
    "    get_url = requests.get('https://www.truecar.com/used-cars-for-sale/listings/?page=' + str(website_number))\n",
    "    return BeautifulSoup(get_url.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = list(map(get_soups, list(range(2501, 2506))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_scraper(soup):\n",
    "    nth_urls = []\n",
    "    def urlsppage(nth):\n",
    "        finding = soup.find_all('a', {'data-test': 'usedListing'})[nth]\n",
    "        return re.findall('href=\"/.+\" style', str(finding)[:280])[0]\n",
    "    nth_urls = list(map(urlsppage, list(range(30))))\n",
    "    return nth_urls\n",
    "\n",
    "urls_list = list(map(urls_scraper, soups))\n",
    "pages_urls = np.array(urls_list).flatten()\n",
    "url_formatter = np.vectorize(lambda url: 'https://truecar.com' + url[6: -7])\n",
    "urls = url_formatter(pages_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscraper(url, feature):\n",
    "    nth_request = requests.get(url)\n",
    "    nth_soup = BeautifulSoup(nth_request.content, 'lxml')\n",
    "    nth_search = re.search(feature + '</h4><ul><li>.+</li', str(nth_soup))\n",
    "    try:\n",
    "        return re.findall('li>.+</l', str(nth_search))[0][3: -3]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First part of vehicles features scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_types = list(map(fscraper, urls, itertools.repeat('Drive Type')))\n",
    "fuel_types = list(map(fscraper, urls, itertools.repeat('Fuel Type')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileages = list(map(fscraper, urls, itertools.repeat('Mileage')))\n",
    "transmissions = list(map(fscraper, urls, itertools.repeat('Transmission')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPGs = list(map(fscraper, urls, itertools.repeat('MPG')))\n",
    "options_levels = list(map(fscraper, urls, itertools.repeat('Options Level')))\n",
    "bed_lengths = list(map(fscraper, urls, itertools.repeat('Bed Length')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = list(map(fscraper, urls, itertools.repeat('Engine')))\n",
    "exterior_colors = list(map(fscraper, urls, itertools.repeat('Exterior Color')))\n",
    "interior_colors = list(map(fscraper, urls, itertools.repeat('Interior Color')))\n",
    "styles = list(map(fscraper, urls, itertools.repeat('Style')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicles Years, Makes and Models scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def ymm_scraper(url, index):\n",
    "    nth_request = requests.get(url)\n",
    "    nth_soup = BeautifulSoup(nth_request.content, 'lxml')\n",
    "    nth_finding = nth_soup.find_all('div', {'class': 'text-truncate heading-3 margin-right-2 margin-right-sm-3'})\n",
    "    try:\n",
    "        if index == 2:\n",
    "            return re.findall('>.+<', str(nth_search))[0][1: -1].split()[2:]\n",
    "        else:\n",
    "            return re.findall('>.+<', str(nth_search))[0][1: -1].split()[index]\n",
    "    except:\n",
    "        return np.NaN'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ymm_scraper(url, feat_name):\n",
    "    nth_request = requests.get(url)\n",
    "    nth_soup = BeautifulSoup(nth_request.content, 'lxml')\n",
    "    nth_finding = nth_soup.find_all('div', {'class': 'text-truncate heading-3 margin-right-2 margin-right-sm-3'})\n",
    "    try:\n",
    "        if feat_name == 'year':\n",
    "            return re.findall('>.+</', str(b))[0].split()[0][1:]\n",
    "        elif feat_name == 'make':\n",
    "            return ' '.join(re.findall('>.+</', str(b))[0].split()[1: -1])[1: -2]\n",
    "        else:\n",
    "            return re.findall('>.+</', str(b))[0].split()[-1][0][: -2]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(map(ymm_scraper, urls, itertools.repeat('year')))\n",
    "makes = list(map(ymm_scraper, urls, itertools.repeat('make')))\n",
    "models = list(map(ymm_scraper, urls, itertools.repeat('models')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicles Prices scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prices_scraper(url):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml').find_all('div', {'data-qa': 'LabelBlock-text'})\n",
    "    try:\n",
    "        return re.findall('[0-9]+,[0-9]+', str(nth_soup))[0]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = list(map(prices_scraper, urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicles Locations (Cities and States) scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cities_scraper(url):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml').find_all('span', {'data-qa': 'used-vdp-header-location'})\n",
    "    try:\n",
    "        return re.findall('\">.+<!', str(nth_soup))[0][2: -12]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def states_scraper(url):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml').find_all('span', {'data-qa': 'used-vdp-header-location'})\n",
    "    try:\n",
    "        return re.findall('[A-W][A-Z]', str(nth_soup))[0]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = list(map(cities_scraper, urls))\n",
    "states = list(map(states_scraper, urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicles Conditions scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions_scraper(url):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml').find_all('li', {'class': '_h9wfdq'})\n",
    "    try:\n",
    "        return re.findall('\">[0-9]<!', str(nth_soup[0]))[0][2: -2] + re.findall('->.+</l', str(nth_soup[0]))[0][2: -3]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = list(map(conditions_scraper, urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'Make': makes, 'Model': models, 'Year': years, 'Mileage': mileages, 'Transmission': transmissions,\n",
    "    'Engine': engines, 'Exterior Color': exterior_colors, 'Interior Color': interior_colors,\n",
    "    'MPG': MPGs, 'Fuel Type': fuel_types, 'Drive Type': drive_types, 'Location (City)': cities,\n",
    "    'Location (State)': states, 'Style': styles, 'Condition (Accidents)': conditions,\n",
    "    'Options Level': options_levels, 'Bed Length': bed_lengths, 'Price': prices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_data = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
