{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import re\n",
    "import requests\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_agg\n",
    "import matplotlib.figure\n",
    "import seaborn as sb\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES PRICES SCRAPING FROM WEB PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_url = 'https://www.truecar.com/used-cars-for-sale/listings/'\n",
    "url_requested = requests.get(fst_page_url)\n",
    "fst_page_soup = BeautifulSoup(url_requested.content, 'lxml')\n",
    "fst_page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_prices = fst_page_soup.find_all('h4', {'data-test': 'vehicleCardPricingBlockPrice'})\n",
    "fst_page_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('[0-9]+,[0-9]+', str(fst_page_prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GET THE RAW HTML SOUPS FROM ALL 600 WEB PAGES\n",
    "\n",
    "def get_soups(website_number):\n",
    "    get_url = requests.get('https://www.truecar.com/used-cars-for-sale/listings/?page=' + str(website_number))\n",
    "    return BeautifulSoup(get_url.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = list(map(get_soups, list(range(1, 600))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO SCRAPE THE CARS PRICES FOR EACH WEB PAGE\n",
    "\n",
    "def pricesscraper(soup):\n",
    "    nth_page_prices_soup = soup.find_all('h4', {'data-test': 'vehicleCardPricingBlockPrice'})\n",
    "    nth_page_prices = re.findall('[0-9]+,[0-9]+', str(nth_page_prices_soup))\n",
    "    return nth_page_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = list(map(pricesscraper, soups))\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = str(prices).replace('[', '').replace(']', '').split(', ')\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = list(map(lambda x: x[1:-1], prices))\n",
    "print(len(prices))\n",
    "prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES YEARS SCRAPING FROM WEB PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_years_soup = fst_page_soup.find_all('span', {'class': 'vehicle-card-year'})\n",
    "fst_page_years_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('[12][0-9]{3}', str(fst_page_years_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO SCRAPE A FEATURE FROM EACH SOUP AND RETURN THE FEATURES LIST\n",
    "\n",
    "def scraper(tag, element, element_description, regex):\n",
    "    def features_scraper(soup):\n",
    "        nth_page_features_soup = soup.find_all(tag, {element: element_description})\n",
    "        nth_page_features = re.findall(regex, str(nth_page_features_soup))\n",
    "        return nth_page_features\n",
    "    features = list(map(features_scraper, soups))\n",
    "    features = str(features).replace('[', '').replace(']', '').split(', ')\n",
    "    features = list(map(lambda x: x[1: -1], features))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = scraper('span', 'class', 'vehicle-card-year', '[12][0-9]{3}')\n",
    "print(len(years))\n",
    "years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES LOCATIONS STATES SCRAPING FROM WEB PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_states_soup = fst_page_soup.find_all('div', {'data-test': 'vehicleCardLocation'})\n",
    "fst_page_states_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('[A-W][A-Y]', str(fst_page_states_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = scraper('div', 'data-test', 'vehicleCardLocation', '[A-Z]{2}')\n",
    "print(len(states))\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES LOCATIONS CITIES SCRAPING FROM WEB PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_cities_soup = fst_page_soup.find_all('div', {'data-test': 'vehicleCardLocation'})\n",
    "fst_page_cities_soup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('[A-Z][a-z]+[. ]*[A-Z]*[a-z]*[. ]*[A-Z]*[a-z]*', str(fst_page_cities_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_unf = scraper('div', 'data-test', 'vehicleCardLocation', '[A-Z][a-z]+[. ]*[A-Z]*[a-z]*[. ]*[A-Z]*[a-z]*')\n",
    "print(len(cities_unf))\n",
    "cities_unf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [city for city in cities_unf if cities_unf.index(city) in list(range(3, len(cities_unf), 4))]\n",
    "print(len(cities))\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES EXTERIOR COLORS SCRAPING FROM WEP PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_colors_soup = fst_page_soup.find_all('div', {'data-test': 'vehicleCardColors'})\n",
    "fst_page_colors_soup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('->[A-Z][a-z]+', str(fst_page_colors_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exterior_colors_unf = scraper('div', 'data-test', 'vehicleCardColors', 'g>[A-Z][a-z]+')\n",
    "len(exterior_colors_unf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exterior_colors = list(map(lambda color: color[2:], exterior_colors_unf))\n",
    "print(len(exterior_colors))\n",
    "exterior_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES INTERIOR COLORS SCRAPING FROM WEB PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('->[A-Z][a-z]+', str(fst_page_colors_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interior_colors_unf = scraper('div', 'data-test', 'vehicleCardColors', '->[A-Z][a-z]+')\n",
    "interior_colors = list(map(lambda color: color[2:], interior_colors_unf))\n",
    "print(len(interior_colors))\n",
    "interior_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEHICLES CONDITION (NUMBER OF ACCIDENTS) SCRAPING FROM WEB PAGE LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_accidents_soup = fst_page_soup.find_all('div', {'data-test': 'vehicleCardCondition'})\n",
    "fst_page_accidents_soup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('[0-9]*[A-z]* accident[s]*', str(fst_page_accidents_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents = scraper('div', 'data-test', 'vehicleCardCondition', '[0-9]*[A-z]* accident[s]*')\n",
    "print(len(accidents))\n",
    "accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URLs Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_page_urls = np.array([])\n",
    "for ind in range(33):\n",
    "    finding = soups[0].find_all('a', {'data-test': 'usedListing'})[ind]\n",
    "    fst_page_urls = np.append(fst_page_urls, re.findall('href=\".+\" style', str(finding)[:280]))\n",
    "print(len(fst_page_urls))\n",
    "fst_page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_scraper(soup):\n",
    "    nth_urls = []\n",
    "    for nth in range(30):\n",
    "        finding = soup.find_all('a', {'data-test': 'usedListing'})[nth]\n",
    "        nth_urls.append(re.findall('href=\"/.+\" style', str(finding)[:280])[0])\n",
    "    return nth_urls\n",
    "rest_urls_list = list(map(urls_scraper, soups[1:]))\n",
    "rest_urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_pages_urls = np.array(rest_urls_list).flatten()\n",
    "all_urls = np.append(fst_page_urls, rest_pages_urls)\n",
    "url_formatter = np.vectorize(lambda url: 'https://truecar.com' + url[6: -7])\n",
    "urls = url_formatter(all_urls)\n",
    "print(len(urls))\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE STYLES SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scraper_from_url(feature_as_argument):\n",
    "    def feature_from_url(url):\n",
    "        nth_request = requests.get(url)\n",
    "        nth_soup = BeautifulSoup(nth_request.content, 'lxml')\n",
    "        nth_search = re.search(feature_as_argument + '</h4><ul><li>.+</li', str(nth_soup))\n",
    "        return re.findall('li>.+</l', str(nth_search))\n",
    "    features_unf = list(map(feature_from_url, urls))\n",
    "    features = list(map(lambda f: str(f)[5: -5], features_unf))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = feature_scraper_from_url('Style')\n",
    "print(len(styles))\n",
    "styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE OPTIONS LEVELS SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_level = feature_scraper_from_url('Options Level')\n",
    "print(len(options_level))\n",
    "options_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE BED LENGTHS SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bed_lengths = feature_scraper_from_url('Bed Length')\n",
    "print(len(bed_lengths))\n",
    "bed_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES MILEAGE PER GALLONS SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPGs = feature_scraper_from_url('MPG')\n",
    "print(len(MPGs))\n",
    "MPGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES DRIVE TYPES SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_types = feature_scraper_from_url('Drive Type')\n",
    "print(len(drive_types))\n",
    "drive_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES FUEL TYPES SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_types = feature_scraper_from_url('Fuel Type')\n",
    "print(len(fuel_types))\n",
    "fuel_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES TRANSMISSIONS SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmissions = feature_scraper_from_url('Transmission')\n",
    "print(len(transmissions))\n",
    "transmissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES MILEAGES SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mileages = feature_scraper_from_url('Mileage')\n",
    "print(len(mileages))\n",
    "mileages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLES ENGINES SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('<li>.+', str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engines_scraper(url):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml')\n",
    "    nth_finding = re.search('Engine</h4><ul><li>.+</li>', str(nth_soup))\n",
    "    return re.findall('<li>.+', str(nth_finding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines_unf = list(map(engines_scraper, urls))\n",
    "engines_unf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_from_url(url):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml')\n",
    "    nth_finding = re.findall('Engine</h4><ul><li>.+</li>', str(nth_soup))\n",
    "    return re.findall('[^><]+', str(nth_finding))[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = list(map(engine_from_url, urls))\n",
    "print(len(engines))\n",
    "engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE MAKES SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeModel_from_url(url, index):\n",
    "    nth_request = requests.get(url).content\n",
    "    nth_soup = BeautifulSoup(nth_request, 'lxml')\n",
    "    nth_finding = nth_soup.find_all('div', {'class': 'text-truncate heading-3 margin-right-2 margin-right-sm-3'})\n",
    "    nth_regex_finding = re.findall('[0-9]{4} .+<', str(nth_finding))\n",
    "    make_model = re.findall('[A-z]+ [A-z]+', str(nth_regex_finding))[0]\n",
    "    return make_model.split()[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makes = list(map(MakeModel_from_url, urls, itertools.repeat(0, len(urls))))\n",
    "print(len(makes))\n",
    "makes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE MODELS SCRAPING FROM WEB PAGES LISTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(map(MakeModel_from_url, urls, itertools.repeat(1, len(urls))))\n",
    "print(len(models))\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'Make': makes, 'Model': models, 'Year': years, 'Price': prices, 'Engine': engines, 'Mileage': mileages,\n",
    "    'Interior Color': interior_colors, 'Exterior Color': exterior_colors, 'Drive Type': drive_types, \n",
    "    'Fuel Type': fuel_types, 'Transmission': transmissions, 'MPG': MPGs, 'Style': styles, \n",
    "    'Bed Length': bed_lengths, 'Location (City)': cities, 'Location (State)': states\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.DataFrame(columns)\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
